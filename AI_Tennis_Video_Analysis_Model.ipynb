{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3lqzftvwAqMp",
        "outputId": "e8fa01b1-89ac-44a4-e489-c81a2e2f21a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.2-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.8-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.3.2-py3-none-any.whl (881 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.4/881.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.2 ultralytics-thop-2.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CANM-vr9iryY"
      },
      "source": [
        "### Player Tracker (player_tracker.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF3_qh4K8qqs",
        "outputId": "fa436ce5-c971-46fe-adb1-d378e8543bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import pickle\n",
        "class PlayerTracker:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "    def choose_and_filter_players(self, court_keypoints, player_detections):\n",
        "        player_detections_first_frame = player_detections[0]\n",
        "        chosen_player = self.choose_players(court_keypoints, player_detections_first_frame)\n",
        "        filtered_player_detections = []\n",
        "        for player_dict in player_detections:\n",
        "            filtered_player_dict = {track_id: bbox for track_id, bbox in player_dict.items() if track_id in chosen_player}\n",
        "            filtered_player_detections.append(filtered_player_dict)\n",
        "        return filtered_player_detections\n",
        "    def choose_players(self, court_keypoints, player_dict):\n",
        "        distances = []\n",
        "        for track_id, bbox in player_dict.items():\n",
        "            player_center = get_center_of_bbox(bbox)\n",
        "\n",
        "            min_distance = float('inf')\n",
        "            for i in range(0,len(court_keypoints),2):\n",
        "                court_keypoint = (court_keypoints[i], court_keypoints[i+1])\n",
        "                distance = measure_distance(player_center, court_keypoint)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "            distances.append((track_id, min_distance))\n",
        "\n",
        "        # sorrt the distances in ascending order\n",
        "        distances.sort(key = lambda x: x[1])\n",
        "        # Choose the first 2 tracks\n",
        "        chosen_players = [distances[0][0], distances[1][0]]\n",
        "        return chosen_players\n",
        "\n",
        "\n",
        "    def detect_frames(self, frames, read_from_stub=False, stub_path=None):\n",
        "        player_detections = []\n",
        "        if read_from_stub and stub_path is not None:\n",
        "            with open(stub_path,'rb') as f:\n",
        "                player_detections=pickle.load(f)\n",
        "            return player_detections\n",
        "\n",
        "        for frame in frames:\n",
        "            player_dict = self.detect_frame(frame)\n",
        "            player_detections.append(player_dict)\n",
        "\n",
        "        if stub_path is not None:\n",
        "            with open(stub_path,'wb') as f:\n",
        "                pickle.dump(player_detections,f)\n",
        "\n",
        "        return player_detections\n",
        "\n",
        "\n",
        "    def detect_frame(self, frame):\n",
        "        results = self.model.track(frame, persist=True)[0]\n",
        "        id_name_dict = results.names\n",
        "        player_dict = {}\n",
        "        for box in results.boxes:\n",
        "            track_id = int(box.id.tolist()[0])\n",
        "            result = box.xyxy.tolist()[0]\n",
        "            object_cls_id = box.cls.tolist()[0]\n",
        "            object_cls_name = id_name_dict[object_cls_id]\n",
        "            if object_cls_name == \"person\":\n",
        "                player_dict[track_id] = result\n",
        "        return player_dict\n",
        "\n",
        "    def draw_bboxes(self, video_frames, player_detections):\n",
        "        output_video_frames = []\n",
        "        for frame, player_dict in zip(video_frames, player_detections):\n",
        "            # Draw bounding boxes\n",
        "            for track_id, bbox in player_dict.items():\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                cv2.putText(frame, f\"Player ID: {track_id}\", (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
        "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "            output_video_frames.append(frame)\n",
        "        return output_video_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULePE2dxiwRx"
      },
      "source": [
        "### Ball Tracker (ball_tracker.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KYFAO2Eiyix"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class BallTracker:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "    def interpolate_ball_positions(self, ball_positions):\n",
        "        ball_positions = [x.get(1,[]) for x in ball_positions]\n",
        "        # convert the list into pandas dataframe\n",
        "        df_ball_positions = pd.DataFrame(ball_positions,columns=['x1','y1','x2','y2'])\n",
        "\n",
        "        # interpolate the missing values\n",
        "        df_ball_positions = df_ball_positions.interpolate()\n",
        "        df_ball_positions = df_ball_positions.bfill()\n",
        "\n",
        "        ball_positions = [{1:x} for x in df_ball_positions.to_numpy().tolist()]\n",
        "\n",
        "        return ball_positions\n",
        "\n",
        "    def detect_frames(self, frames, read_from_stub=False, stub_path=None):\n",
        "        ball_detections = []\n",
        "        if read_from_stub and stub_path is not None:\n",
        "            with open(stub_path,'rb') as f:\n",
        "                ball_detections=pickle.load(f)\n",
        "            return ball_detections\n",
        "\n",
        "        for frame in frames:\n",
        "            player_dict = self.detect_frame(frame)\n",
        "            ball_detections.append(player_dict)\n",
        "\n",
        "        if stub_path is not None:\n",
        "            with open(stub_path,'wb') as f:\n",
        "                pickle.dump(ball_detections,f)\n",
        "\n",
        "        return ball_detections\n",
        "\n",
        "    def detect_frame(self, frame):\n",
        "        results = self.model.predict(frame, conf=0.15)[0]\n",
        "        ball_dict = {}\n",
        "        for box in results.boxes:\n",
        "            result = box.xyxy.tolist()[0]\n",
        "            ball_dict[1] = result\n",
        "        return ball_dict\n",
        "\n",
        "    def draw_bboxes(self, video_frames, ball_detections):\n",
        "        output_video_frames = []\n",
        "        for frame, ball_dict in zip(video_frames, ball_detections):\n",
        "            # Draw bounding boxes\n",
        "            for track_id, bbox in ball_dict.items():\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                cv2.putText(frame, f\"Ball ID: {track_id}\", (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
        "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
        "            output_video_frames.append(frame)\n",
        "        return output_video_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maBVTl-Sntc6"
      },
      "source": [
        "### video_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpjEASbmADs8"
      },
      "outputs": [],
      "source": [
        "#bbox_utils.py\n",
        "\n",
        "def get_center_of_bbox(bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    center_x = int((x1 + x2) / 2)\n",
        "    center_y = int((y1 + y2) / 2)\n",
        "    return (center_x, center_y)\n",
        "def measure_distance(p1,p2):\n",
        "    return ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**0.5\n",
        "def get_foot_position(bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    return (int((x1 + x2) / 2), y2)\n",
        "\n",
        "def get_closest_keypoint_index(point, keypoints, keypoint_indices):\n",
        "   closest_distance = float('inf')\n",
        "   key_point_ind = keypoint_indices[0]\n",
        "   for keypoint_indix in keypoint_indices:\n",
        "       keypoint = keypoints[keypoint_indix*2], keypoints[keypoint_indix*2+1]\n",
        "       distance = abs(point[1]-keypoint[1])\n",
        "\n",
        "       if distance<closest_distance:\n",
        "           closest_distance = distance\n",
        "           key_point_ind = keypoint_indix\n",
        "\n",
        "   return key_point_ind\n",
        "\n",
        "def get_height_of_bbox(bbox):\n",
        "    return bbox[3]-bbox[1]\n",
        "\n",
        "def measure_xy_distance(p1,p2):\n",
        "    return abs(p1[0]-p2[0]), abs(p1[1]-p2[1])\n",
        "\n",
        "def get_center_of_bbox(bbox):\n",
        "    return (int((bbox[0]+bbox[2])/2),int((bbox[1]+bbox[3])/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pRZI4eLiyKT"
      },
      "source": [
        "### Conversions.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aXYdKYfiw3C"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_pixel_distance_to_meters(pixel_distance, refrence_height_in_meters, refrence_height_in_pixels):\n",
        "    return (pixel_distance * refrence_height_in_meters) / refrence_height_in_pixels\n",
        "\n",
        "def convert_meters_to_pixel_distance(meters, refrence_height_in_meters, refrence_height_in_pixels):\n",
        "    return (meters * refrence_height_in_pixels) / refrence_height_in_meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJvrBNCo_dmb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def read_video(video_path):\n",
        "  cap=cv2.VideoCapture(video_path)\n",
        "  frames=[]\n",
        "  while cap.isOpened():\n",
        "    ret,frame=cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    frames.append(frame)\n",
        "  cap.release()\n",
        "  return frames\n",
        "\n",
        "def save_video(output_video_frames,output_video_path):\n",
        "  height, width = output_video_frames[0].shape[:2]\n",
        "  fourcc=cv2.VideoWriter_fourcc(*'MJPG')\n",
        "  out=cv2.VideoWriter(output_video_path,fourcc,24,(width,height))\n",
        "  for frame in output_video_frames:\n",
        "    out.write(frame)\n",
        "  out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WpcYxC7rd_v",
        "outputId": "0296e1de-e4df-42bd-d6a4-997e5fa5b57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open tennis_court_det_dataset.zip, tennis_court_det_dataset.zip.zip or tennis_court_det_dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip tennis_court_det_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRzX7Q7Nrg_p",
        "outputId": "cdfe6a14-b976-4d76-c88a-0f572f32d38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import  Dataset, DataLoader\n",
        "from torchvision  import transforms, utils, models\n",
        "\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLd0X4EhrlkL"
      },
      "outputs": [],
      "source": [
        "class KeypointCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KeypointCNN, self).__init__()\n",
        "        \n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 14 * 2)  # 14 keypoints (x, y)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        \n",
        "        # Flattening output\n",
        "        x = x.view(-1, 128 * 28 * 28)\n",
        "        \n",
        "        # Forward pass through fully connected layers\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class KeypointsDataset(Dataset):\n",
        "    def __init__(self, img_dir, data_file):\n",
        "        self.img_dir = img_dir\n",
        "        with open(data_file, 'r') as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
        "        h, w = img.shape[:2]\n",
        "        \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.transforms(img)\n",
        "        kps = np.array(item['kps']).flatten()\n",
        "        kps = kps.astype(np.float32)\n",
        "\n",
        "        # Adjust coordinates to the new image size\n",
        "        kps[::2] = 224.0 / w * kps[::2]\n",
        "        kps[1::2] = 224.0 / h * kps[1::2]\n",
        "\n",
        "        return img, kps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "JjfsTz-UrniZ",
        "outputId": "232372f3-9d6c-4a3b-812d-1d4a6b9fe116"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/data_train.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e6aea69d9b77>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeypointsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data/data_train.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeypointsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data/data_val.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-799ac6159e15>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir, data_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_train.json'"
          ]
        }
      ],
      "source": [
        "train_dataset = KeypointsDataset(\"data/images\",'data/data_train.json')\n",
        "val_dataset = KeypointsDataset(\"data/images\",'data/data_val.json')\n",
        "\n",
        "train_loader = DataLoader(train_dataset ,batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "bL-UdFz4rpNl",
        "outputId": "86c7d57a-e9ea-4705-cadc-9310f70823de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 124MB/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fd5097ce4d62>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mkps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "# Create model, loss function, and optimizer\n",
        "model = KeypointCNN().to(dev)  # Replace ResNet with custom CNN\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for i, (imgs, kps) in enumerate(train_loader):\n",
        "        imgs = imgs.to(dev)\n",
        "        kps = kps.to(dev)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, kps)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")\n",
        "\n",
        "# Saving the trained model\n",
        "torch.save(model.state_dict(), 'keypoints_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep3W6TOyrYLG"
      },
      "source": [
        "### Tennis Court Keypoints Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8KhUaDqoUTd"
      },
      "source": [
        "### Court Line Detector (court_line_detector.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZlHd7ajoTu1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CourtLineDetector:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = models.resnet50(pretrained=True)\n",
        "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, 14*2)\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')), strict=False)\n",
        "\n",
        "        self.transforms = transforms.Compose([\n",
        "          transforms.ToPILImage(),\n",
        "          transforms.Resize((224, 224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def predict(self, image):\n",
        "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image_tensor = self.transforms(img_rgb)\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          outputs = self.model(image_tensor)\n",
        "\n",
        "        keypoints = outputs.squeeze().numpy()\n",
        "        org_h, org_w = img_rgb.shape[:2]\n",
        "\n",
        "        keypoints[::2] *= org_w/224.0\n",
        "        keypoints[1::2] *= org_h/224.0\n",
        "\n",
        "        return keypoints\n",
        "\n",
        "    def draw_keypoints(self, image, keypoints):\n",
        "        for i in range(0, len(keypoints), 2):\n",
        "          x, y = int(keypoints[i]), int(keypoints[i+1])\n",
        "\n",
        "          cv2.putText(image, str(i//2), (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "          cv2.circle(image, (x, y), 5, (0, 0, 255), -1)\n",
        "        return image\n",
        "\n",
        "    def draw_keypoints_on_video(self, video_frames, keypoints):\n",
        "        output_video_frames = []\n",
        "        for frame in video_frames:\n",
        "          frame = self.draw_keypoints(frame, keypoints)\n",
        "          output_video_frames.append(frame)\n",
        "        return output_video_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq1vv9cLgqM6"
      },
      "source": [
        "### Defining constants for drawing the mini court\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er63B3eBgL2d"
      },
      "outputs": [],
      "source": [
        "SINGLE_LINE_WIDTH = 8.23\n",
        "DOUBLE_LINE_WIDTH = 10.97\n",
        "HALF_COURT_LINE_HEIGHT = 11.88\n",
        "SERVICE_LINE_WIDTH = 6.4\n",
        "DOUBLE_ALLY_DIFFERENCE = 1.37\n",
        "NO_MANS_LAND_HEIGHT = 5.48\n",
        "\n",
        "PLAYER_1_HEIGHT_METERS = 1.88\n",
        "PLAYER_2_HEIGHT_METERS = 1.91"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXNcMLtxg3kT"
      },
      "source": [
        "### mini_court.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAcgVm8GgzxP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "class MiniCourt():\n",
        "  def __init__(self,frame):\n",
        "          self.drawing_rectangle_width = 250\n",
        "          self.drawing_rectangle_height = 500\n",
        "          self.buffer = 50\n",
        "          self.padding_court=20\n",
        "\n",
        "          self.set_canvas_background_box_position(frame)\n",
        "          self.set_mini_court_position()\n",
        "          self.set_court_drawing_key_points()\n",
        "          self.set_court_lines()\n",
        "  def convert_meters_to_pixels(self, meters):\n",
        "          return convert_meters_to_pixel_distance(meters,\n",
        "                                                  DOUBLE_LINE_WIDTH,\n",
        "                                                  self.court_drawing_width\n",
        "                                              )\n",
        "  def set_court_drawing_key_points(self):\n",
        "          drawing_key_points = [0]*28\n",
        "          # point 0\n",
        "          drawing_key_points[0] , drawing_key_points[1] = int(self.court_start_x), int(self.court_start_y)\n",
        "          # point 1\n",
        "          drawing_key_points[2] , drawing_key_points[3] = int(self.court_end_x), int(self.court_start_y)\n",
        "          # point 2\n",
        "          drawing_key_points[4] = int(self.court_start_x)\n",
        "          drawing_key_points[5] = self.court_start_y + self.convert_meters_to_pixels(HALF_COURT_LINE_HEIGHT*2)\n",
        "          # point 3\n",
        "          drawing_key_points[6] = drawing_key_points[0] + self.court_drawing_width\n",
        "          drawing_key_points[7] = drawing_key_points[5]\n",
        "          # #point 4\n",
        "          drawing_key_points[8] = drawing_key_points[0] +  self.convert_meters_to_pixels(DOUBLE_ALLY_DIFFERENCE)\n",
        "          drawing_key_points[9] = drawing_key_points[1]\n",
        "          # #point 5\n",
        "          drawing_key_points[10] = drawing_key_points[4] + self.convert_meters_to_pixels(DOUBLE_ALLY_DIFFERENCE)\n",
        "          drawing_key_points[11] = drawing_key_points[5]\n",
        "          # #point 6\n",
        "          drawing_key_points[12] = drawing_key_points[2] - self.convert_meters_to_pixels(DOUBLE_ALLY_DIFFERENCE)\n",
        "          drawing_key_points[13] = drawing_key_points[3]\n",
        "          # #point 7\n",
        "          drawing_key_points[14] = drawing_key_points[6] - self.convert_meters_to_pixels(DOUBLE_ALLY_DIFFERENCE)\n",
        "          drawing_key_points[15] = drawing_key_points[7]\n",
        "          # #point 8\n",
        "          drawing_key_points[16] = drawing_key_points[8]\n",
        "          drawing_key_points[17] = drawing_key_points[9] + self.convert_meters_to_pixels(NO_MANS_LAND_HEIGHT)\n",
        "          # # #point 9\n",
        "          drawing_key_points[18] = drawing_key_points[16] + self.convert_meters_to_pixels(SINGLE_LINE_WIDTH)\n",
        "          drawing_key_points[19] = drawing_key_points[17]\n",
        "          # #point 10\n",
        "          drawing_key_points[20] = drawing_key_points[10]\n",
        "          drawing_key_points[21] = drawing_key_points[11] - self.convert_meters_to_pixels(NO_MANS_LAND_HEIGHT)\n",
        "          # # #point 11\n",
        "          drawing_key_points[22] = drawing_key_points[20] +  self.convert_meters_to_pixels(SINGLE_LINE_WIDTH)\n",
        "          drawing_key_points[23] = drawing_key_points[21]\n",
        "          # # #point 12\n",
        "          drawing_key_points[24] = int((drawing_key_points[16] + drawing_key_points[18])/2)\n",
        "          drawing_key_points[25] = drawing_key_points[17]\n",
        "          # # #point 13\n",
        "          drawing_key_points[26] = int((drawing_key_points[20] + drawing_key_points[22])/2)\n",
        "          drawing_key_points[27] = drawing_key_points[21]\n",
        "\n",
        "          self.drawing_key_points=drawing_key_points\n",
        "\n",
        "  def convert_bounding_boxes_to_mini_court_coordinates(self,player_boxes, ball_boxes, original_court_key_points ):\n",
        "        player_heights = {\n",
        "            1: PLAYER_1_HEIGHT_METERS,\n",
        "            2: PLAYER_2_HEIGHT_METERS\n",
        "        }\n",
        "\n",
        "        output_player_boxes= []\n",
        "        output_ball_boxes= []\n",
        "\n",
        "        for frame_num, player_bbox in enumerate(player_boxes):\n",
        "            ball_box = ball_boxes[frame_num][1]\n",
        "            ball_position = get_center_of_bbox(ball_box)\n",
        "\n",
        "            #Handle cases with more than two players by selecting the two closest to the ball.\n",
        "            closest_player_ids_to_ball = sorted(player_bbox.keys(), key=lambda x: measure_distance(ball_position, get_center_of_bbox(player_bbox[x])))[:2]\n",
        "\n",
        "            output_player_bboxes_dict = {}\n",
        "            for player_id in closest_player_ids_to_ball: # Only iterate over the two closest players\n",
        "                bbox = player_bbox[player_id]\n",
        "                foot_position = get_foot_position(bbox)\n",
        "\n",
        "                # Get The closest keypoint in pixels\n",
        "                closest_key_point_index = get_closest_keypoint_index(foot_position,original_court_key_points, [0,2,12,13])\n",
        "                closest_key_point = (original_court_key_points[closest_key_point_index*2],\n",
        "                                     original_court_key_points[closest_key_point_index*2+1])\n",
        "\n",
        "                # Get Player height in pixels\n",
        "                frame_index_min = max(0, frame_num-20)\n",
        "                frame_index_max = min(len(player_boxes), frame_num+50)\n",
        "                bboxes_heights_in_pixels = [get_height_of_bbox(player_boxes[i][player_id]) for i in range (frame_index_min,frame_index_max)]\n",
        "                max_player_height_in_pixels = max(bboxes_heights_in_pixels)\n",
        "\n",
        "                mini_court_player_position = self.get_mini_court_coordinates(foot_position,\n",
        "                                                                            closest_key_point,\n",
        "                                                                            closest_key_point_index,\n",
        "                                                                            max_player_height_in_pixels,\n",
        "                                                                            player_heights.get(player_id, 1.88) # Use a default height if player_id not in dict\n",
        "                                                                            )\n",
        "\n",
        "                output_player_bboxes_dict[player_id] = mini_court_player_position\n",
        "\n",
        "                if player_id in closest_player_ids_to_ball:\n",
        "                    # Get The closest keypoint in pixels\n",
        "                    closest_key_point_index = get_closest_keypoint_index(ball_position,original_court_key_points, [0,2,12,13])\n",
        "                    closest_key_point = (original_court_key_points[closest_key_point_index*2],\n",
        "                                        original_court_key_points[closest_key_point_index*2+1])\n",
        "\n",
        "                    mini_court_player_position = self.get_mini_court_coordinates(ball_position,\n",
        "                                                                            closest_key_point,\n",
        "                                                                            closest_key_point_index,\n",
        "                                                                            max_player_height_in_pixels,\n",
        "                                                                            player_heights.get(player_id, 1.88) # Use a default height if player_id not in dict\n",
        "                                                                            )\n",
        "                    output_ball_boxes.append({1:mini_court_player_position})\n",
        "            output_player_boxes.append(output_player_bboxes_dict)\n",
        "\n",
        "        return output_player_boxes , output_ball_boxes\n",
        "\n",
        "        return output_player_boxes , output_ball_boxes\n",
        "  def get_mini_court_coordinates(self,\n",
        "                                   object_position,\n",
        "                                   closest_key_point,\n",
        "                                   closest_key_point_index,\n",
        "                                   player_height_in_pixels,\n",
        "                                   player_height_in_meters\n",
        "                                   ):\n",
        "\n",
        "        distance_from_keypoint_x_pixels, distance_from_keypoint_y_pixels = measure_xy_distance(object_position, closest_key_point)\n",
        "\n",
        "        # Conver pixel distance to meters\n",
        "        distance_from_keypoint_x_meters = convert_pixel_distance_to_meters(distance_from_keypoint_x_pixels,\n",
        "                                                                           player_height_in_meters,\n",
        "                                                                           player_height_in_pixels\n",
        "                                                                           )\n",
        "        distance_from_keypoint_y_meters = convert_pixel_distance_to_meters(distance_from_keypoint_y_pixels,\n",
        "                                                                                player_height_in_meters,\n",
        "                                                                                player_height_in_pixels\n",
        "                                                                          )\n",
        "\n",
        "        # Convert to mini court coordinates\n",
        "        mini_court_x_distance_pixels = self.convert_meters_to_pixels(distance_from_keypoint_x_meters)\n",
        "        mini_court_y_distance_pixels = self.convert_meters_to_pixels(distance_from_keypoint_y_meters)\n",
        "        closest_mini_coourt_keypoint = ( self.drawing_key_points[closest_key_point_index*2],\n",
        "                                        self.drawing_key_points[closest_key_point_index*2+1]\n",
        "                                        )\n",
        "\n",
        "        mini_court_player_position = (closest_mini_coourt_keypoint[0]+mini_court_x_distance_pixels,\n",
        "                                      closest_mini_coourt_keypoint[1]+mini_court_y_distance_pixels\n",
        "                                        )\n",
        "\n",
        "        return  mini_court_player_position\n",
        "\n",
        "\n",
        "  def set_court_lines(self):\n",
        "        self.lines = [\n",
        "            (0, 2),\n",
        "            (4, 5),\n",
        "            (6,7),\n",
        "            (1,3),\n",
        "\n",
        "            (0,1),\n",
        "            (8,9),\n",
        "            (10,11),\n",
        "            (10,11),\n",
        "            (2,3)\n",
        "        ]\n",
        "  def set_mini_court_position(self):\n",
        "          self.court_start_x = self.start_x + self.padding_court\n",
        "          self.court_start_y = self.start_y + self.padding_court\n",
        "          self.court_end_x = self.end_x - self.padding_court\n",
        "          self.court_end_y = self.end_y - self.padding_court\n",
        "          self.court_drawing_width = self.court_end_x - self.court_start_x\n",
        "\n",
        "\n",
        "  def set_canvas_background_box_position(self,frame):\n",
        "          frame= frame.copy()\n",
        "\n",
        "          self.end_x = frame.shape[1] - self.buffer\n",
        "          self.end_y = self.buffer + self.drawing_rectangle_height\n",
        "          self.start_x = self.end_x - self.drawing_rectangle_width\n",
        "          self.start_y = self.end_y - self.drawing_rectangle_height\n",
        "  def draw_court(self,frame):\n",
        "        for i in range(0, len(self.drawing_key_points),2):\n",
        "            x = int(self.drawing_key_points[i])\n",
        "            y = int(self.drawing_key_points[i+1])\n",
        "            cv2.circle(frame, (x,y),5, (0,0,255),-1)\n",
        "\n",
        "        # draw Lines\n",
        "        for line in self.lines:\n",
        "            start_point = (int(self.drawing_key_points[line[0]*2]), int(self.drawing_key_points[line[0]*2+1]))\n",
        "            end_point = (int(self.drawing_key_points[line[1]*2]), int(self.drawing_key_points[line[1]*2+1]))\n",
        "            cv2.line(frame, start_point, end_point, (0, 0, 0), 2)\n",
        "\n",
        "        # Draw net\n",
        "        net_start_point = (self.drawing_key_points[0], int((self.drawing_key_points[1] + self.drawing_key_points[5])/2))\n",
        "        net_end_point = (self.drawing_key_points[2], int((self.drawing_key_points[1] + self.drawing_key_points[5])/2))\n",
        "        cv2.line(frame, net_start_point, net_end_point, (255, 0, 0), 2)\n",
        "\n",
        "        return frame\n",
        "  def draw_background_rectangle(self,frame):\n",
        "        shapes = np.zeros_like(frame,np.uint8)\n",
        "        # Draw the rectangle\n",
        "        cv2.rectangle(shapes, (self.start_x, self.start_y), (self.end_x, self.end_y), (255, 255, 255), cv2.FILLED)\n",
        "        out = frame.copy()\n",
        "        alpha=0.5\n",
        "        mask = shapes.astype(bool)\n",
        "        out[mask] = cv2.addWeighted(frame, alpha, shapes, 1 - alpha, 0)[mask]\n",
        "\n",
        "        return out\n",
        "  def draw_mini_court(self,frames):\n",
        "        output_frames = []\n",
        "        for frame in frames:\n",
        "            frame = self.draw_background_rectangle(frame)\n",
        "            frame = self.draw_court(frame)\n",
        "            output_frames.append(frame)\n",
        "        return output_frames\n",
        "  def draw_points_on_mini_court(self,frames,postions, color=(0,255,0)):\n",
        "        for frame_num, frame in enumerate(frames):\n",
        "            for _, position in postions[frame_num].items():\n",
        "                x,y = position\n",
        "                x= int(x)\n",
        "                y= int(y)\n",
        "                cv2.circle(frame, (x,y), 5, color, -1)\n",
        "        return frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztD64giMkgpm"
      },
      "source": [
        "### main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "UWqsS15J_THD",
        "outputId": "bbd2f82f-fd20-4378-96d1-896b8cd17fe9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_video_path=\"/content/drive/MyDrive/AI_Project_Models/input_video.mp4\"\n",
        "video_frames = read_video(input_video_path)\n",
        "\n",
        "player_tracker = PlayerTracker(model_path='yolov8x')\n",
        "ball_tracker = BallTracker(model_path='/content/drive/MyDrive/AI_Project_Models/yolov5_best.pt')\n",
        "\n",
        "player_detections=player_tracker.detect_frames(video_frames,\n",
        "                                               read_from_stub=True,\n",
        "                                               stub_path='/content/drive/MyDrive/AI_Project_Models/tracker_stubs/player_detections.pkl')\n",
        "ball_detections=ball_tracker.detect_frames(video_frames,\n",
        "                                           read_from_stub=True,\n",
        "                                           stub_path='/content/drive/MyDrive/AI_Project_Models/tracker_stubs/ball_detections.pkl')\n",
        "ball_detections = ball_tracker.interpolate_ball_positions(ball_detections)\n",
        "\n",
        "court_line_detector = CourtLineDetector(model_path='/content/drive/MyDrive/AI_Project_Models/keypoints_model.pth')\n",
        "court_keypoints = court_line_detector.predict(video_frames[0])\n",
        "import cv2\n",
        "output_video_frames = player_tracker.draw_bboxes(video_frames,player_detections)\n",
        "output_video_frames = ball_tracker.draw_bboxes(output_video_frames,ball_detections)\n",
        "output_video_frames = court_line_detector.draw_keypoints_on_video(video_frames,court_keypoints)\n",
        "\n",
        "# Draw Mini Court\n",
        "mini_court = MiniCourt(video_frames[0])\n",
        "player_mini_court_detections,ball_mini_court_detections = mini_court.convert_bounding_boxes_to_mini_court_coordinates(player_detections,\n",
        "                                                                                                          ball_detections,\n",
        "                                                                                                          court_keypoints)\n",
        "\n",
        "output_video_frames = mini_court.draw_mini_court(output_video_frames)\n",
        "output_video_frames = mini_court.draw_points_on_mini_court(output_video_frames,player_mini_court_detections)\n",
        "output_video_frames = mini_court.draw_points_on_mini_court(output_video_frames,ball_mini_court_detections, color=(0,255,255))\n",
        "\n",
        "#frame number top left corner\n",
        "for i, frame in enumerate(output_video_frames):\n",
        "      cv2.putText(frame, f\"Frame: {i}\",(10,30),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "save_video(output_video_frames,\"/content/drive/MyDrive/AI_Project_Models/output_video_interpolation.avi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040lQ7nwnAhp",
        "outputId": "1a8a1347-e58a-4951-b599-17d3e96f2eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ULePE2dxiwRx"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
